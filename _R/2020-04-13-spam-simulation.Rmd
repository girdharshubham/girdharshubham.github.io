---
layout: post
title: "The 'spam comments' puzzle: tidy simulation of stochastic processes in R"
description: "Solving a puzzle from 538's The Riddler column: if new spam comments appear at an average rate of one per day, including on other spam comments, how many can we expect after three days?"
output: html_document
date: 2020-04-13 14:00:00 -0400
category: r
tags: [r, statistics]
comments: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, cache = TRUE)

library(ggplot2)
theme_set(theme_light())
```

**Previously in this series**:

* [The "lost boarding pass" puzzle](http://varianceexplained.org/r/boarding-pass-simulation/)
* [The "deadly board game" puzzle](http://varianceexplained.org/r/board-game-simulation/)
* [The "knight on an infinite chessboard" puzzle](http://varianceexplained.org/r/knight-chess/)
* [The "largest stock profit or loss" puzzle](http://varianceexplained.org/r/stock-changes/)
* [The "birthday paradox" puzzle](http://varianceexplained.org/r/birthday-problem/)
* [The "Spelling Bee honeycomb" puzzle](http://varianceexplained.org/r/honeycomb-puzzle/)
* [Feller's "coin-tossing" puzzle](http://varianceexplained.org/r/feller-coins/)

I love 538's Riddler column, and the [April 10 puzzle](https://fivethirtyeight.com/features/can-you-catch-the-free-t-shirt/) is another interesting one. I'll quote:

> Over the course of three days, suppose the probability of any spammer making a new comment on this week’s Riddler column over a very short time interval is proportional to the length of that time interval. (For those in the know, I’m saying that spammers follow a [Poisson process](https://mathworld.wolfram.com/PoissonProcess.html).) On average, the column gets one brand-new comment of spam per day that is not a reply to any previous comments. Each spam comment or reply also gets its own spam reply at an average rate of one per day.

> For example, after three days, I might have four comments that were not replies to any previous comments, and each of them might have a few replies (and their replies might have replies, which might have further replies, etc.).

> After the three days are up, how many total spam posts (comments plus replies) can I expect to have?

This is a great opportunity for tidy simulation in R, and also for reviewing some of the concepts of stochastic processes. As we'll see, it's even thematically relevant to current headlines, since it involves exponential growth.

Solving a puzzle generally includes a few false starts, especially as we go from an estimated answer to an exact mathematical one. So I recorded [this screencast](https://www.youtube.com/watch?v=QtThluGted0) showing how I approached the problem from scratch. It shows not only how to perform the simulation, but how to use those results to guide the way to an exact answer.

### Simulating a Poisson process

The Riddler puzzle describes a Poisson process, which is one of the most important stochastic processes. A Poisson process models the intuitive concept of "an event is equally likely to happen at any moment." It's named because the number of events occurring in a time interval of length $$x$$ is distributed according to $$\mbox{Pois}(\lambda x)$$, for some rate parameter $$\lambda$$ (for this puzzle, the rate is described as one per day, $$\lambda=1$$).

How can we simulate a Poisson process? This is an important connection between distributions. The *waiting time* for the next event in a Poisson process has an [exponential distribution](https://en.wikipedia.org/wiki/Exponential_distribution), which can be simulated with `rexp()`.

```{r echo = FALSE, cache = FALSE}
set.seed(2020-04-13)
```

```{r cache = FALSE}
# The rate parameter, 1, is the expected events per day
waiting <- rexp(10, 1)
waiting
```

For example, in this case we waited `r round(waiting[1], 2)` days for the first comment, then `r round(waiting[2], 2)` after that for the second one, and so on. On average, we'll be waiting one day for each new comment, but it could be a lot longer or shorter.

You can take the cumulative sum of these waiting periods to come up with the event times (new comments) in the Poisson process.

```{r cache = FALSE}
qplot(cumsum(waiting), 0)
```

### Simulating a Yule process

Before the first comment happened, the rate of new comments/replies was 1 per day. But as soon as the first comment happened, the rate increased: the comment could spawn its own replies, so the rate went up to 2 per day. Once there were two comments, the rate goes up to 3 per day, and so on.

This is a particular case of a stochastic process known as a [Yule process](https://en.wikipedia.org/wiki/Yule%E2%80%93Simon_distribution) (which is a special case of a [**birth process**](https://en.wikipedia.org/wiki/Birth%E2%80%93death_process), a continuous-time Markov chain where the state is always increasing). We could prove a lot of mathematical properties of that process, but let's focus on simulating it.

The waiting time for the first comment would be $$\mbox{Exponential}(1)$$, but the waiting time for the second is $$\mbox{Exponential}(2)$$, then $$\mbox{Exponential}(3)$$, and so on. We can use the vectorized `rexp()` function to simulate those. The waiting times will, on average, get shorter and shorter as there are more comments that can spawn replies.

```{r cache = FALSE}
set.seed(2020)
```

```{r cache = FALSE}
waiting_times <- rexp(20, 1:20)

# Cumulative time
cumsum(waiting_times)

# Number before the third day
sum(cumsum(waiting_times) < 3)
```

In this case, the first 15 events happened before the third day. Notice that in this simulation, we're not keeping track of *which* comment received a reply: we're treating all the comments as interchangeable. This lets our simulation run a lot faster since we just have to generate the waiting times.

All combined, we could perform this simulation in one line:

```{r}
sum(cumsum(rexp(20, 1:20)) < 3)
```

So in one line with `replicate()`, here's one million simulations. We simulate 300 waiting periods from each, and see how many happen before the first day.

```{r sim}
sim <- replicate(1e6, sum(cumsum(rexp(300, 1:300)) < 3))

mean(sim)
```

It looks like it's about 19.1.

### Turning this into an exact solution 

Why 19.1? Could we get an exact answer that is intuitively satisfying?

One trick to get a foothold is to vary one of our inputs: rather than looking at 3 days, let's look at the expected comments after time $$t$$. That's easier if we expand this into a tidy simulation, using one of my favorite functions `crossing()` (from tidyr).

```{r sim_waiting}
library(tidyverse)
set.seed(2020)

sim_waiting <- crossing(trial = 1:25000,
         observation = 1:300) %>%
  mutate(waiting = rexp(n(), observation)) %>%
  group_by(trial) %>%
  mutate(cumulative = cumsum(waiting)) %>%
  ungroup()

sim_waiting
```

We can confirm that the average number of comments in the first three days is about 19.

```{r dependson = "sim_waiting"}
sim_waiting %>%
  group_by(trial) %>%
  summarize(num_comments = sum(cumulative <= 3)) %>%
  summarize(average = mean(num_comments))
```

But we can also use `crossing()` (again) to look at the expected number of cumulative comments as we vary $$t$$.

```{r average_over_time, dependson = "sim_waiting"}
average_over_time <- sim_waiting %>%
  crossing(time = seq(0, 3, .25)) %>%
  group_by(time, trial) %>%
  summarize(num_comments = sum(cumulative < time)) %>%
  summarize(average = mean(num_comments))
```

(Notice how often "solve the problem for one value" can be turned into "solve the problem for many values" with one use of `crossing()`: one of my favorite tricks).

How does the average number of comments increase over time?

```{r dependson = "average_over_time"}
ggplot(average_over_time, aes(time, average)) +
  geom_line()
```

At a glance, this looks like an exponential curve. With a little experimentation, and noticing that the curve starts at $$(0, 0)$$, we can find that the expected number of comments at time $$t$$ follows $$e^t-1$$. This fits with our simulation: $$e^3 - 1$$ is 19.0855.

```{r dependson = "average_over_time"}
ggplot(average_over_time, aes(time, average)) +
  geom_line(aes(y = exp(time) - 1), color = "red") +
  geom_point() +
  labs(y = "Average # of comments",
       title = "How many comments over time?",
       subtitle = "Points show simulation, red line shows exp(time) - 1.")
```

Intuitively, it makes sense that on average the growth is exponential. If we'd described the process as "bacteria in a dish, each of which could divide at any moment", we'd expect exponential growth. The "minus one" is because the original post is generating comments just like all the others do, but doesn't itself count as a comment.[^minusone]

### Distribution of comments at a given time

It's worth noting we're still only describing an **average** path. There could easily be more, or fewer, spam comments by the third day. This wasn't a part of the riddle, but we might be interested in the variation of results.

Our tidy simulation gives us a way to plot many such paths.

```{r dependson = "sim_waiting"}
sim_waiting %>%
  filter(trial <= 50, cumulative <= 3) %>%
  ggplot(aes(cumulative, observation)) +
  geom_line(aes(group = trial), alpha = .25) +
  geom_line(aes(y = exp(cumulative) - 1), color = "red", size = 1) +
  labs(x = "Time",
       y = "# of comments",
       title = "50 possible paths of comments over time",
       subtitle = "Red line shows e^t - 1")
```

The red line shows the overall average, reaching about 19.1 at 3 days. However, we can see that it can sometimes be much smaller or much larger (even even more than 100).

What is the probability distribution of comments after three days- the probability there is one comment, or two, or three? Let's take a look at the distribution.

```{r num_comments, dependson = "sim"}
# We'll use the million simulated values from earlier
num_comments <- tibble(num_comments = sim)

num_comments %>%
  ggplot(aes(num_comments)) +
  geom_histogram(binwidth = 1)
```

Interestingly, at a glance this looks a lot like an exponential curve. Since it's a discrete distribution (with values 0, 1, 2...), this suggests it's a [geometric distribution](https://en.wikipedia.org/wiki/Geometric_distribution): the expected number of "tails" flipped before we see the first "heads".

We can confirm that by comparing it to the probability mass function, $$(1-p)^np$$. If it is a geometric distribution, then because we know the expected value is $$e^3-1$$ we know the rate parameter $$p$$ (the probability of a success on each heads) is $$\frac{1}{e^3}=e^{-3}$$.

```{r dependson = "num_comments"}
p <- exp(-3)

num_comments %>%
  filter(num_comments <= 150) %>%
  ggplot(aes(num_comments)) +
  geom_histogram(aes(y = ..density..), binwidth = 1) +
  geom_line(aes(y = (1 - p) ^ num_comments * p), color = "red")
```

This isn't a mathematical proof, but it's very compelling. So what we've learned overall is:

$$X(t)\sim \mbox{Geometric}(e^{-t})$$
$$E[X(t)]= e^{-t}-1$$

These are true because the rate of comments is one per day. If the rate of new comments were $$\lambda$$, you'd replace $$t$$ above with $$\lambda t$$.

I don't have an immediate intuition for why the distribution is geometric. Though it's interesting that the parameter $$p=e^{-t}$$ for the geometric distribution (the probability of a "success" on the coin flip that would stop the process) is equal to the probability that there are *no* events in time $$t$$ for a Poisson process.

### Conclusion: Yule process

I wasn't familiar with the term "Yule process" when I first started solving the riddle, and you can see in the [screencast](https://www.youtube.com/watch?v=QtThluGted0) how I started with just the simulation's approximate result and walked my way to an the understanding the mathematical properties. (For confirmation of some of the results above you can check out [this paper](https://projecteuclid.org/download/pdf_1/euclid.ecp/1465058863) or this [Wikipedia entry](https://en.wikipedia.org/wiki/Yule%E2%80%93Simon_distribution), among others.)

What I love about simulation is how it builds an intuition for problems like this from the ground up. These simulated datasets and visualizations are a better "handle" for me for grasp the concepts than mathematical equations would be. After I've gotten a feel for the distributions, I can check my answer, and learn more, by looking through the mathematical literature.

[^minusone]: If you don't like the $$-1$$, you could have counted the post as a comment, started everything out at $$X(0)=1$$, and then you would find that $$E[X(t)]=e^t$$. This is the more traditional definition of a Yule process.